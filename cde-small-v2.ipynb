{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dbc262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jxm/cde-small-v2:\n",
      "- model.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled 23 dropout modules from model type <class 'transformers_modules.jxm.cde-small-v2.4e1d021a6c3fd7ce8aa0a7204057eee5ae61d390.model.BiEncoder'>\n",
      "Disabled 46 dropout modules from model type <class 'transformers_modules.jxm.cde-small-v2.4e1d021a6c3fd7ce8aa0a7204057eee5ae61d390.model.ContextualDocumentEmbeddingTransformer'>\n",
      "CDE v2 minicorpus size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/soray/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:282: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 임베딩 크기: torch.Size([51628, 768])\n",
      "질의 임베딩 크기: torch.Size([6640, 768])\n"
     ]
    }
   ],
   "source": [
    "# ==== 0) 환경 준비 ====\n",
    "import os, random, math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "model_name = \"jxm/cde-small-v2\"\n",
    "model = transformers.AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# 프리픽스 정의\n",
    "query_prefix    = \"search_query: \"\n",
    "document_prefix = \"search_document: \"\n",
    "\n",
    "# 모델 config에서 minicorpus 크기 확인\n",
    "minicorpus_size = getattr(model.config, \"transductive_corpus_size\", 512)\n",
    "print(\"CDE v2 minicorpus size:\", minicorpus_size)\n",
    "\n",
    "df_train = pd.read_csv(\"/home/alpaco/sryang/Training.csv\")\n",
    "df_valid = pd.read_csv(\"/home/alpaco/sryang/validation.csv\")\n",
    "\n",
    "train_docs = df_train.iloc[:,0].dropna().astype(str).tolist()  \n",
    "val_queries = df_valid.iloc[:,0].dropna().astype(str).tolist() \n",
    "\n",
    "minicorpus_size = getattr(model.config, \"transductive_corpus_size\", 512)\n",
    "if len(train_docs) >= minicorpus_size:\n",
    "    minicorpus_docs = random.sample(train_docs, k=minicorpus_size)\n",
    "else:\n",
    "    reps = math.ceil(minicorpus_size / max(1, len(train_docs)))\n",
    "    minicorpus_docs = (train_docs * reps)[:minicorpus_size]\n",
    "\n",
    "mc_tok = tokenizer(\n",
    "    [document_prefix + d for d in minicorpus_docs],\n",
    "    truncation=True, padding=True, max_length=768, return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "# ====  1단계 임베딩 ====\n",
    "batch_size = 32\n",
    "dataset_embeddings = []\n",
    "for i in range(0, mc_tok[\"input_ids\"].size(0), batch_size):\n",
    "    batch = {k: v[i:i+batch_size] for k, v in mc_tok.items()}\n",
    "    with torch.no_grad():\n",
    "        emb = model.first_stage_model(**batch)\n",
    "    dataset_embeddings.append(emb)\n",
    "dataset_embeddings = torch.cat(dataset_embeddings, dim=0).to(device)\n",
    "\n",
    "# ====  문서 임베딩 ====\n",
    "docs_tok = tokenizer(\n",
    "    [document_prefix + d for d in train_docs],\n",
    "    truncation=True, padding=True, max_length=768, return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "doc_embeddings = []\n",
    "for i in range(0, docs_tok[\"input_ids\"].size(0), batch_size):\n",
    "    batch = {k: v[i:i+batch_size] for k, v in docs_tok.items()}\n",
    "    with torch.no_grad():\n",
    "        emb = model.second_stage_model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            dataset_embeddings=dataset_embeddings\n",
    "        )\n",
    "        emb = torch.nn.functional.normalize(emb, p=2, dim=1)\n",
    "    doc_embeddings.append(emb)\n",
    "doc_embeddings = torch.cat(doc_embeddings, dim=0).to(device)\n",
    "\n",
    "# ====  질의 임베딩 ====\n",
    "q_tok = tokenizer(\n",
    "    [query_prefix + q for q in val_queries],\n",
    "    truncation=True, padding=True, max_length=512, return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "query_embeddings = []\n",
    "for i in range(0, q_tok[\"input_ids\"].size(0), batch_size):\n",
    "    batch = {k: v[i:i+batch_size] for k, v in q_tok.items()}\n",
    "    with torch.no_grad():\n",
    "        emb = model.second_stage_model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            dataset_embeddings=dataset_embeddings\n",
    "        )\n",
    "        emb = torch.nn.functional.normalize(emb, p=2, dim=1)\n",
    "    query_embeddings.append(emb)\n",
    "query_embeddings = torch.cat(query_embeddings, dim=0).to(device)\n",
    "\n",
    "print(\"문서 임베딩 크기:\", doc_embeddings.shape)\n",
    "print(\"질의 임베딩 크기:\", query_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f616e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset_embeddings.cpu(), \"/home/alpaco/sryang/embedding_result/cde_minicorpus.pt\")\n",
    "torch.save(doc_embeddings.cpu(), \"/home/alpaco/sryang/embedding_result/cde_doc.pt\")\n",
    "torch.save(query_embeddings.cpu(), \"/home/alpaco/sryang/embedding_result/cde_query_emb.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
